{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f29a99-d1ed-485d-a8df-c636badbb77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py  (수정판: 핵심만 고침)\n",
    "import torch, torch.nn.functional as F, torch.nn as nn\n",
    "from model import custom_res18\n",
    "from dataset import full_forget_retain_loader_train, full_forget_retain_loader_test,  UnlearnFullTrain\n",
    "from train_test_acc import train_model, model_test\n",
    "from mia_unlearning_score import UnLearningScore, get_membership_attack_prob, actv_dist\n",
    "from seed import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH = 512\n",
    "EPOCHS = 20\n",
    "epoch_unlearn = 10\n",
    "LR = 1e-4\n",
    "TAU_G, TAU_B = 1, 1    # 실험용 기본\n",
    "FORGET_RATIO = 0.1\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc441e0-434b-4dcf-a86e-1151d0ea3ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "full_tr, combined_tr, forget_tr, retain_tr = full_forget_retain_loader_train(FORGET_RATIO, batch_size=BATCH)\n",
    "full_te, combined_te, forget_te, retain_te = full_forget_retain_loader_test(FORGET_RATIO, batch_size=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ae1bbd-fced-4f69-a0ba-2e4c7f3693b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/khw/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/khw/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train:good_teacher] Epoch 1/20 Loss 2.1895 Acc 25.88%\n",
      "[Train:good_teacher] Epoch 2/20 Loss 1.3927 Acc 48.45%\n",
      "[Train:good_teacher] Epoch 3/20 Loss 1.0711 Acc 61.51%\n",
      "[Train:good_teacher] Epoch 4/20 Loss 0.8547 Acc 69.47%\n",
      "[Train:good_teacher] Epoch 5/20 Loss 0.6721 Acc 76.10%\n",
      "[Train:good_teacher] Epoch 6/20 Loss 0.5399 Acc 80.91%\n",
      "[Train:good_teacher] Epoch 7/20 Loss 0.4031 Acc 85.77%\n",
      "[Train:good_teacher] Epoch 8/20 Loss 0.2985 Acc 89.44%\n",
      "[Train:good_teacher] Epoch 9/20 Loss 0.2159 Acc 92.44%\n",
      "[Train:good_teacher] Epoch 10/20 Loss 0.1625 Acc 94.36%\n",
      "[Train:good_teacher] Epoch 11/20 Loss 0.1343 Acc 95.27%\n",
      "[Train:good_teacher] Epoch 12/20 Loss 0.1105 Acc 96.19%\n",
      "[Train:good_teacher] Epoch 13/20 Loss 0.0739 Acc 97.59%\n",
      "[Train:good_teacher] Epoch 14/20 Loss 0.0521 Acc 98.32%\n",
      "[Train:good_teacher] Epoch 15/20 Loss 0.0553 Acc 98.20%\n",
      "[Train:good_teacher] Epoch 16/20 Loss 0.0547 Acc 98.22%\n",
      "[Train:good_teacher] Epoch 17/20 Loss 0.0519 Acc 98.33%\n",
      "[Train:good_teacher] Epoch 18/20 Loss 0.0583 Acc 98.01%\n",
      "[Train:good_teacher] Epoch 19/20 Loss 0.0583 Acc 98.10%\n",
      "[Train:good_teacher] Epoch 20/20 Loss 0.0513 Acc 98.39%\n",
      "[Train:retrain_retains_only] Epoch 1/20 Loss 2.0540 Acc 29.06%\n",
      "[Train:retrain_retains_only] Epoch 2/20 Loss 1.3922 Acc 48.90%\n",
      "[Train:retrain_retains_only] Epoch 3/20 Loss 1.1384 Acc 59.07%\n",
      "[Train:retrain_retains_only] Epoch 4/20 Loss 0.9061 Acc 67.80%\n",
      "[Train:retrain_retains_only] Epoch 5/20 Loss 0.7445 Acc 73.90%\n",
      "[Train:retrain_retains_only] Epoch 6/20 Loss 0.5794 Acc 79.44%\n",
      "[Train:retrain_retains_only] Epoch 7/20 Loss 0.4452 Acc 84.32%\n",
      "[Train:retrain_retains_only] Epoch 8/20 Loss 0.3217 Acc 88.69%\n",
      "[Train:retrain_retains_only] Epoch 9/20 Loss 0.2423 Acc 91.40%\n",
      "[Train:retrain_retains_only] Epoch 10/20 Loss 0.1821 Acc 93.64%\n",
      "[Train:retrain_retains_only] Epoch 11/20 Loss 0.1501 Acc 94.87%\n",
      "[Train:retrain_retains_only] Epoch 12/20 Loss 0.0900 Acc 96.93%\n",
      "[Train:retrain_retains_only] Epoch 13/20 Loss 0.0704 Acc 97.69%\n",
      "[Train:retrain_retains_only] Epoch 14/20 Loss 0.0652 Acc 97.78%\n",
      "[Train:retrain_retains_only] Epoch 15/20 Loss 0.0797 Acc 97.23%\n",
      "[Train:retrain_retains_only] Epoch 16/20 Loss 0.0774 Acc 97.30%\n",
      "[Train:retrain_retains_only] Epoch 17/20 Loss 0.0714 Acc 97.55%\n",
      "[Train:retrain_retains_only] Epoch 18/20 Loss 0.0447 Acc 98.58%\n",
      "[Train:retrain_retains_only] Epoch 19/20 Loss 0.0215 Acc 99.39%\n",
      "[Train:retrain_retains_only] Epoch 20/20 Loss 0.0114 Acc 99.74%\n"
     ]
    }
   ],
   "source": [
    "# Good Teacher 학습 및 저장\n",
    "good = custom_res18(NUM_CLASSES).to(DEVICE)\n",
    "good = train_model(\n",
    "    good,\n",
    "    combined_tr.dataset,\n",
    "    'good_teacher',\n",
    "    epochs=EPOCHS, lr=LR, batch_size=BATCH, device=DEVICE\n",
    ")\n",
    "torch.save(good.state_dict(), './full_tr_model.pth')\n",
    "\n",
    "# Retain 전용 재학습 모델\n",
    "retrain = custom_res18(NUM_CLASSES).to(DEVICE)\n",
    "retrain = train_model(\n",
    "    retrain,\n",
    "    retain_tr.dataset,  # retain 데이터만 사용\n",
    "    'retrain_retains_only',\n",
    "    epochs=EPOCHS,\n",
    "    lr=LR, batch_size=BATCH,\n",
    "    device=DEVICE\n",
    ")\n",
    "torch.save(retrain.state_dict(), './retrain_tr_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6420394-afe4-421c-bb11-bb069fb5f896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test:bad/full_test] Acc 78.42%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_test(good, full_te.dataset, 'bad/full_test', batch_size=256, device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69943c27-48e6-4e85-aa97-a7a8544fdaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train:finetune] Epoch 1/20 Loss 0.0244 Acc 99.28%\n",
      "[Train:finetune] Epoch 2/20 Loss 0.0210 Acc 99.45%\n",
      "[Train:finetune] Epoch 3/20 Loss 0.0201 Acc 99.45%\n",
      "[Train:finetune] Epoch 4/20 Loss 0.0231 Acc 99.39%\n",
      "[Train:finetune] Epoch 5/20 Loss 0.0307 Acc 99.06%\n",
      "[Train:finetune] Epoch 6/20 Loss 0.0894 Acc 96.97%\n",
      "[Train:finetune] Epoch 7/20 Loss 0.1267 Acc 95.59%\n",
      "[Train:finetune] Epoch 8/20 Loss 0.0759 Acc 97.53%\n",
      "[Train:finetune] Epoch 9/20 Loss 0.0364 Acc 98.95%\n",
      "[Train:finetune] Epoch 10/20 Loss 0.0198 Acc 99.49%\n",
      "[Train:finetune] Epoch 11/20 Loss 0.0089 Acc 99.83%\n",
      "[Train:finetune] Epoch 12/20 Loss 0.0032 Acc 99.96%\n",
      "[Train:finetune] Epoch 13/20 Loss 0.0013 Acc 99.99%\n",
      "[Train:finetune] Epoch 14/20 Loss 0.0011 Acc 100.00%\n",
      "[Train:finetune] Epoch 15/20 Loss 0.0012 Acc 100.00%\n",
      "[Train:finetune] Epoch 16/20 Loss 0.0014 Acc 100.00%\n",
      "[Train:finetune] Epoch 17/20 Loss 0.0015 Acc 100.00%\n",
      "[Train:finetune] Epoch 18/20 Loss 0.0016 Acc 100.00%\n",
      "[Train:finetune] Epoch 19/20 Loss 0.0017 Acc 100.00%\n",
      "[Train:finetune] Epoch 20/20 Loss 0.0017 Acc 100.00%\n",
      "\n",
      "[Accuracies]\n",
      "[Test:Finetune/Retain_test] Acc 84.97%\n",
      "[Test:Finetune/Forget_test] Acc 87.00%\n",
      "[Test:Finetune/Retain_train] Acc 100.00%\n",
      "[Test:Finetune/Forget_train] Acc 96.68%\n",
      "\n",
      "[MIA]\n",
      "  MIA success prob on Forget (test) : 0.4873\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "finetune_model = custom_res18(NUM_CLASSES).to(DEVICE)\n",
    "finetune_model.load_state_dict(torch.load('./full_tr_model.pth'))\n",
    "\n",
    "# 파인튜닝\n",
    "finetune_model = train_model(\n",
    "    finetune_model,\n",
    "    retain_tr.dataset,   # train_model 안에서 DataLoader 만들 수 있다고 가정\n",
    "    'finetune',\n",
    "    epochs=EPOCHS, lr=LR, batch_size=BATCH, device=DEVICE\n",
    ")\n",
    "\n",
    "finetune_model.eval()\n",
    "\n",
    "print('\\n[Accuracies]')\n",
    "model_test(finetune_model, retain_te.dataset, 'Finetune/Retain_test', batch_size=256, device=DEVICE)\n",
    "model_test(finetune_model, forget_te.dataset, 'Finetune/Forget_test', batch_size=256, device=DEVICE)\n",
    "model_test(finetune_model, retain_tr.dataset, 'Finetune/Retain_train', batch_size=256, device=DEVICE)\n",
    "model_test(finetune_model, forget_tr.dataset, 'Finetune/Forget_train', batch_size=256, device=DEVICE)\n",
    "\n",
    "# 평가용 DataLoader (batch 크기/셔플 옵션 다르게 주고 싶을 때)\n",
    "forget_eval_train = torch.utils.data.DataLoader(forget_tr.dataset,  batch_size=128, shuffle=False)\n",
    "forget_eval_test  = torch.utils.data.DataLoader(forget_te.dataset,  batch_size=128, shuffle=False)\n",
    "retain_eval_train = torch.utils.data.DataLoader(retain_tr.dataset,  batch_size=128, shuffle=False)\n",
    "retain_eval_test  = torch.utils.data.DataLoader(retain_te.dataset,  batch_size=128, shuffle=False)\n",
    "\n",
    "print('\\n[MIA]')\n",
    "mia_p = get_membership_attack_prob(retain_eval_train, forget_eval_test, retain_eval_test, finetune_model, DEVICE)\n",
    "print(f'  MIA success prob on Forget (test) : {mia_p:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d62a96-114e-4ae5-a986-caa2a983f2db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (khw)",
   "language": "python",
   "name": "ft_transformer_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
